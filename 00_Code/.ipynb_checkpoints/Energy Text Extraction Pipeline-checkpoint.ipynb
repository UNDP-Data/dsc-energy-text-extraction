{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c69dba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from pdfminer.high_level import extract_text\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse   \n",
    "import numpy as np\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26fe72",
   "metadata": {},
   "source": [
    "<h3> Open Metadata </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcc4fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Metadata CSV\n",
    "\n",
    "metadata_df = pd.read_excel('../01_Input/00_Metadata/National Energy Document Compilation.xlsx')\n",
    "metadata_df=metadata_df[metadata_df[\"Exists?\"]==\"Y\"]\n",
    "\n",
    "metadata_df=metadata_df.head(50)\n",
    "#'../01_Input/00_Metadata/seh-document-metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df116404",
   "metadata": {},
   "source": [
    "<h3> Donwload PDFs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56445f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download a pdf from a url to a path if is exists\n",
    "def download_document(pdf_url,pdf_path):\n",
    "    \n",
    "    # Code to download the document from the URL\n",
    "    # Handle different formats (PDF, HTML, etc.)\n",
    "   \n",
    "    try:\n",
    "        response = requests.get(pdf_url,timeout=8)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            #content_disposition = response.headers.get(\"content-disposition\")\n",
    "\n",
    "            with open(pdf_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "            print(f\"{pdf_path} successfully downloaded document with path: {pdf_url}\")\n",
    "            return pdf_path\n",
    "        else:\n",
    "            print(f\"Code 200, failed to downloaded document with path: {pdf_url}\")\n",
    "            return \"None\"\n",
    "    except:\n",
    "        print(f\"Failure to download document with path: {pdf_url}\")\n",
    "        return \"None\"\n",
    "    \n",
    "#Example Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74d2d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download missing document\n",
    "def download_document_if_missing(row,pdf_path):\n",
    "    if not os.path.exists(pdf_path):\n",
    "        ##Download document if the pdf is not already present\n",
    "        pdf_url = row['Link']\n",
    "        if not pd.isna(pdf_url):\n",
    "            download_document(pdf_url,pdf_path)\n",
    "        else:\n",
    "            print(pdf_path,\"no pdf or link\")\n",
    "    else:\n",
    "        print(pdf_path,\"already exists\")\n",
    "        \n",
    "#Example Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4c7c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the download function for all\n",
    "def download_all(metadata_df,missing_only=True):\n",
    "    \n",
    "    for index, row in metadata_df.iterrows():\n",
    "\n",
    "        folder=\"../01_Input/01_PDFs/03_National/\"+row[\"Code\"].split(\"-\")[0]\n",
    "        # Check if the directory already exists\n",
    "        if not os.path.exists(folder):\n",
    "            # Create the directory\n",
    "            os.makedirs(folder)\n",
    "            print(folder+\"directory created!\")\n",
    "        pdf_path=folder+'/'+row[\"Code\"]+\".pdf\"\n",
    "\n",
    "        download_document_if_missing(row,pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d26609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../01_Input/01_PDFs/03_National/AFG/AFG-CPD-2014-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-CPD-2014-FR.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-CPD-2014-SP.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NEP-2015-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NREP-41365-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NREP-2015-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NRES-2017-PR.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NRER-2017-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NEPro-2022-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NES-2007-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NEEP-2016-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AFG/AFG-NRES-2017-FA.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-CPD-2021-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-CPD-2021-FR.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-CPD-2021-SP.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NES-43101-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NEPro-2022-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NEP-2013-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NREP-2021-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NREP-2021-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NECP-44378-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NETS-2019-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NREAP-2016-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NREAP-2018-AL.pdf already exists\n",
      "Failure to download document with path: https://www.infrastruktura.gov.al/wp-content/uploads/2017/12/WB11-ALB-ENE-01_Institutional_Review_Final_20160418.pdf\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NREAP-2015-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ALB/ALB-NREDS-2005-EN.pdf successfully downloaded document with path: https://unfccc.int/files/meetings/seminar/application/pdf/sem_albania_sup1.pdf\n",
      "Failure to download document with path: https://www.energycharter.org/fileadmin/DocumentsMedia/IDEER/IDEER-Albania_2013_en.pdf\n",
      "../01_Input/01_PDFs/03_National/DZA/DZA-CPD-2023-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/DZA/DZA-CPD-2023-FR.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/DZA/DZA-CPD-2023-SP.pdf already exists\n",
      "Code 200, failed to downloaded document with path: https://www.afdb.org/sites/default/files/documents/projects-and-operations/algeria_-_algeria_renewable_energy_program_arep_-_g-dz-fz0-pre-001_-_par_-_sefa.pdf\n",
      "../01_Input/01_PDFs/03_National/DZA/DZA-NEPro-2022-EN.pdf successfully downloaded document with path: https://www.irena.org/-/media/Files/IRENA/Agency/Statistics/Statistical_Profiles/Africa/Algeria_Africa_RE_SP.pdf?country=Algeria&regionID=&countryID=132f2b7d-a9d0-4e26-85c8-476bcda948ba\n",
      "../01_Input/01_PDFs/03_National/AGO/AGO-CPD-2019-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AGO/AGO-CPD-2019-SP.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/AGO/AGO-CPD-2019-FR.pdf already exists\n",
      "Code 200, failed to downloaded document with path: https://www.afdb.org/sites/default/files/documents/projects-and-operations/angola_-programme_denergie_renouvelable_en_angola_arep-don_sefa_-_rapport_dachevement_de_projet.pdf\n",
      "../01_Input/01_PDFs/03_National/AGO/AGO-NEPro-2022-EN.pdf already exists\n",
      "Code 200, failed to downloaded document with path: https://www.afdb.org/3895a8ee-bcbc-43f0-af5b-6275e7a2aac8\n",
      "../01_Input/01_PDFs/03_National/ARG/ARG-CPD-2021-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARG/ARG-CPD-2021-SP.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARG/ARG-NEPro-2022-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-CPD-2021-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-CPD-2021-SP.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-CPD-2021-FR.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-NEEP-42205-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-NEEP-2010-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-LCEDP-2020-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-SREP-2014-EN.pdf already exists\n",
      "../01_Input/01_PDFs/03_National/ARM/ARM-NRER-2013-AR.pdf already exists\n"
     ]
    }
   ],
   "source": [
    "## Run the download pipeline for all\n",
    "download_all(metadata_df,missing_only=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cf3c6",
   "metadata": {},
   "source": [
    "<h3> Text Extraction </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3eeaa6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract text from document\n",
    "\n",
    "def extract_text_from_pdf(extract_text_path,pdf_path):\n",
    "    try:\n",
    "        text = extract_text(pdf_path)##imported function\n",
    "        ##export text\n",
    "        with open(extract_text_path, 'w') as file:\n",
    "            file.write(text)\n",
    "    except:\n",
    "        print(\"invalid pdf\",pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1fcdc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download missing documents\n",
    "\n",
    "def extract_text_if_missing(extract_text_path,pdf_path):\n",
    "    \n",
    "    if not os.path.exists(extract_text_path):\n",
    "        ##extract text if it is not already present\n",
    "        extract_text_from_pdf(extract_text_path,pdf_path)\n",
    "\n",
    "    else:\n",
    "        print(extract_text_path,\"already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "500afc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the extract function for all\n",
    "def extract_all(metadata_df,missing_only=True):\n",
    "    \n",
    "    for index, row in metadata_df.iterrows():\n",
    "\n",
    "        folder=\"03_National/\"+row[\"Code\"].split(\"-\")[0]## update this for more docs\n",
    "        pdf_path=\"../01_Input/01_PDFs/\"+folder+'/'+row[\"Code\"]+\".pdf\"\n",
    "        extract_text_folder=\"../02_Output/00_Extracted-Text/\"+folder\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            \n",
    "            if not os.path.exists(extract_text_folder):\n",
    "                # Create the directory\n",
    "                os.makedirs(extract_text_folder)\n",
    "                print(extract_text_folder+\"directory created!\")\n",
    "\n",
    "            if missing_only:\n",
    "                extract_text_if_missing(extract_text_folder+'/'+row[\"Code\"]+\".txt\",pdf_path)\n",
    "            else:\n",
    "                extract_text_from_pdf(pdf_path)\n",
    "        else:\n",
    "            print(\"can't extract because no pdf\",row[\"Code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9a0924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-CPD-2014-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-CPD-2014-FR.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-CPD-2014-SP.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NEP-2015-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NREP-41365-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NREP-2015-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NRES-2017-PR.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NRER-2017-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NEPro-2022-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NES-2007-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NEEP-2016-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AFG/AFG-NRES-2017-FA.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-CPD-2021-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-CPD-2021-FR.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-CPD-2021-SP.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NES-43101-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NEPro-2022-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NEP-2013-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NREP-2021-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NREP-2021-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NECP-44378-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NETS-2019-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NREAP-2016-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NREAP-2018-AL.txt already exists\n",
      "can't extract because no pdf ALB-NGP-2016-EN\n",
      "../02_Output/00_Extracted-Text/03_National/ALB/ALB-NREAP-2015-EN.txt already exists\n",
      "invalid pdf ../01_Input/01_PDFs/03_National/ALB/ALB-NREDS-2005-EN.pdf\n",
      "can't extract because no pdf ALB-NREEP-2013-EN\n",
      "../02_Output/00_Extracted-Text/03_National/DZA/DZA-CPD-2023-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/DZA/DZA-CPD-2023-FR.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/DZA/DZA-CPD-2023-SP.txt already exists\n",
      "can't extract because no pdf DZA-NREP-43952-EN\n",
      "../02_Output/00_Extracted-Text/03_National/AGO/AGO-CPD-2019-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AGO/AGO-CPD-2019-SP.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/AGO/AGO-CPD-2019-FR.txt already exists\n",
      "can't extract because no pdf AGO-NREP-2023-FR\n",
      "../02_Output/00_Extracted-Text/03_National/AGO/AGO-NEPro-2022-EN.txt already exists\n",
      "can't extract because no pdf AGO-SEP-2023-EN\n",
      "../02_Output/00_Extracted-Text/03_National/ARG/ARG-CPD-2021-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARG/ARG-CPD-2021-SP.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARG/ARG-NEPro-2022-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-CPD-2021-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-CPD-2021-SP.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-CPD-2021-FR.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-NEEP-42205-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-NEEP-2010-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-LCEDP-2020-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-SREP-2014-EN.txt already exists\n",
      "../02_Output/00_Extracted-Text/03_National/ARM/ARM-NRER-2013-AR.txt already exists\n"
     ]
    }
   ],
   "source": [
    "extract_all(metadata_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6418734d",
   "metadata": {},
   "source": [
    "<h3> Text Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a4983afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text cleaning \n",
    "\n",
    "def remove_noise(text):\n",
    "    cleaned_text = text.replace('\\uf0a7', ';')\n",
    "    cleaned_text = text.replace('\\r', '\\n')\n",
    "    cleaned_text = re.sub(r\"\\n\", \" \", cleaned_text)  # remove newlines\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)  # replace multiple spaces with a single space\n",
    "    # cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", cleaned_text)  # remove non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r\"http\\S+|www\\S+|ftp\\S+\", \"\", cleaned_text) # remove urls\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stopwords(text): \n",
    "    # nltk.download('stopwords') # only need to run this once\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_text = [word for word in text.split() if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "def convert_to_lowercase(text): # reduce words to their root forms\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     # nltk.download('wordnet') only need to run this once\n",
    "#     lemmatizer = WordNetLemmatizer() # tokenize the input text into words\n",
    "#     words = nltk.word_tokenize(text) # lemmatize each word and collect the results in a list\n",
    "\n",
    "#     original_words = []\n",
    "#     lemmatized_words = []\n",
    "#     for word in words:\n",
    "#         original_words.append(word)\n",
    "#         lemmatized_word = lemmatizer.lemmatize(word)\n",
    "#         lemmatized_words.append(lemmatized_word)\n",
    "#         # if word != lemmatized_word: # keep track of lemmatized words\n",
    "#         #     print(f\"Word '{word}' changed to '{lemmatized_word}'\")\n",
    "\n",
    "#     lemmatized_text = \" \".join(lemmatized_words)\n",
    "#     return lemmatized_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7cbe32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(extract_text_path,clean_text_path):\n",
    "    \n",
    "    with open(extract_text_path, 'r') as file:\n",
    "        extract_text=file.read()\n",
    "    \n",
    "    # Remove unwanted characters, whitespace, etc.\n",
    "    # Regular expressions can be helpful here\n",
    "    # Additional cleaning steps as required\n",
    "    \n",
    "    clean_text = remove_noise(extract_text)\n",
    "    # clean_text = remove_punctuation(text)\n",
    "    # clean_text = remove_stopwords(text)\n",
    "    # clean_text = convert_to_lowercase(text)\n",
    "    # clean_text = lemmatize_text(text)\n",
    "    \n",
    "    with open(clean_text_path, 'w') as file:\n",
    "        file.write(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1a01c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_if_missing(extract_text_path,clean_text_path):\n",
    "    \n",
    "    if not os.path.exists(clean_text_path):\n",
    "        ##extract text if it is not already present\n",
    "        clean_text(extract_text_path,clean_text_path)\n",
    "\n",
    "    else:\n",
    "        print(clean_text_path,\"already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26044c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the clean function for all\n",
    "def clean_all(metadata_df,missing_only=True):\n",
    "    \n",
    "    for index, row in metadata_df.iterrows():\n",
    "\n",
    "        folder=\"03_National/\"+row[\"Code\"].split(\"-\")[0]## update this for more docs\n",
    "        \n",
    "        clean_text_folder=\"../02_Output/01_Cleaned-Text/\"+folder\n",
    "        extract_text_folder=\"../02_Output/00_Extracted-Text/\"+folder\n",
    "        \n",
    "        extract_text_path=extract_text_folder+'/'+row[\"Code\"]+\".txt\"\n",
    "        clean_text_path=clean_text_folder+'/'+row[\"Code\"]+\"-clean.txt\"\n",
    "        \n",
    "        if os.path.exists(extract_text_path):\n",
    "            \n",
    "            if not os.path.exists(clean_text_folder):\n",
    "                # Create the directory\n",
    "                os.makedirs(clean_text_folder)\n",
    "                print(clean_text_folder+\"directory created!\")\n",
    "\n",
    "            if missing_only:\n",
    "                clean_text_if_missing(extract_text_path,clean_text_path)\n",
    "            else:\n",
    "                clean_text(extract_text_path,clean_text_path)\n",
    "        else:\n",
    "            print(\"can't clean because no extract\",row[\"Code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e8f1dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-CPD-2014-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-CPD-2014-FR-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-CPD-2014-SP-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NEP-2015-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NREP-41365-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NREP-2015-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NRES-2017-PR-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NRER-2017-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NEPro-2022-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NES-2007-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NEEP-2016-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AFG/AFG-NRES-2017-FA-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-CPD-2021-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-CPD-2021-FR-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-CPD-2021-SP-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NES-43101-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NEPro-2022-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NEP-2013-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NREP-2021-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NREP-2021-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NECP-44378-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NETS-2019-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NREAP-2016-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NREAP-2018-AL-clean.txt already exists\n",
      "can't clean because no extract ALB-NGP-2016-EN\n",
      "../02_Output/01_Cleaned-Text/03_National/ALB/ALB-NREAP-2015-EN-clean.txt already exists\n",
      "can't clean because no extract ALB-NREDS-2005-EN\n",
      "can't clean because no extract ALB-NREEP-2013-EN\n",
      "../02_Output/01_Cleaned-Text/03_National/DZA/DZA-CPD-2023-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/DZA/DZA-CPD-2023-FR-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/DZA/DZA-CPD-2023-SP-clean.txt already exists\n",
      "can't clean because no extract DZA-NREP-43952-EN\n",
      "../02_Output/01_Cleaned-Text/03_National/DZA/DZA-NEPro-2022-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AGO/AGO-CPD-2019-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AGO/AGO-CPD-2019-SP-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/AGO/AGO-CPD-2019-FR-clean.txt already exists\n",
      "can't clean because no extract AGO-NREP-2023-FR\n",
      "../02_Output/01_Cleaned-Text/03_National/AGO/AGO-NEPro-2022-EN-clean.txt already exists\n",
      "can't clean because no extract AGO-SEP-2023-EN\n",
      "../02_Output/01_Cleaned-Text/03_National/ARG/ARG-CPD-2021-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARG/ARG-CPD-2021-SP-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARG/ARG-NEPro-2022-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-CPD-2021-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-CPD-2021-SP-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-CPD-2021-FR-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-NEEP-42205-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-NEEP-2010-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-LCEDP-2020-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-SREP-2014-EN-clean.txt already exists\n",
      "../02_Output/01_Cleaned-Text/03_National/ARM/ARM-NRER-2013-AR-clean.txt already exists\n"
     ]
    }
   ],
   "source": [
    "clean_all(metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbabbc59",
   "metadata": {},
   "source": [
    "<h3> convert final cleaned text and metadata to jsons </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "32e7e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_json(json_path,clean_text_path,row):\n",
    "    \n",
    "    with open(clean_text_path, 'r') as file:\n",
    "        text=file.read()\n",
    "    \n",
    "    document_json = {\n",
    "        'Code': str(row['Code']),\n",
    "        'Status': row['Status'],\n",
    "        'Country Name': row['Country Name'],\n",
    "        'Country Code': str(row['Country Code']),\n",
    "        'Category': row['Category'],\n",
    "        'KeyWord to Search': row['KeyWord to Search'],\n",
    "        'Document Title': row['Title'],\n",
    "        'Exists?': row['Exists?'],\n",
    "        'Category': row['Category'],\n",
    "        'Publication Date': str(row['Publication Date']),\n",
    "        'Publication Year': str(row['Publication Date']),\n",
    "        'Start Year': str(row['Start Year']),\n",
    "        'End Year': str(row['End Year']),\n",
    "        'Language': row['Language'],\n",
    "        'Link': row['Link'],\n",
    "        'Content': text  # Extracted text content from PDF\n",
    "    }\n",
    "\n",
    "\n",
    "    # Write the dictionary to a JSON file\n",
    "    with open(json_path, 'w') as jsonfile:\n",
    "        json.dump(document_json, jsonfile)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b95141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonify_if_missing(json_path,clean_text_path,row):\n",
    "    \n",
    "    if not os.path.exists(json_path):\n",
    "        ##extract text if it is not already present\n",
    "        create_document_json(json_path,clean_text_path,row)\n",
    "\n",
    "    else:\n",
    "        print(json_path,\"already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d127fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonify_all(metadata_df,missing_only=True):\n",
    "    \n",
    "    metadata_df=metadata_df.fillna(np.nan).replace([np.nan], [None])##fixes missing so json works\n",
    "\n",
    "    for index, row in metadata_df.iterrows():\n",
    "\n",
    "        folder=\"03_National/\"+row[\"Code\"].split(\"-\")[0]## update this for more docs\n",
    "        \n",
    "        clean_text_folder=\"../02_Output/01_Cleaned-Text/\"+folder ##later update this to the manual folder\n",
    "        json_folder=\"../02_Output/03_Pdf-Jsons/\"+folder\n",
    "        \n",
    "        clean_text_path=clean_text_folder+'/'+row[\"Code\"]+\"-clean.txt\"\n",
    "        json_path=json_folder+'/'+row[\"Code\"]+\".json\"\n",
    "        \n",
    "        if os.path.exists(clean_text_path):\n",
    "            \n",
    "            if not os.path.exists(json_folder):\n",
    "                # Create the directory\n",
    "                os.makedirs(json_folder)\n",
    "                print(json_folder+\" directory created!\")\n",
    "\n",
    "            if missing_only:\n",
    "                jsonify_if_missing(json_path,clean_text_path,row)\n",
    "            else:\n",
    "                create_document_json(json_path,clean_text_path,row)\n",
    "        else:\n",
    "            print(\"can't jsonify because no clean text\",row[\"Code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0f1b8455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../02_Output/03_Pdf-Jsons/03_National/AFG directory created!\n",
      "../02_Output/03_Pdf-Jsons/03_National/ALB directory created!\n",
      "../02_Output/03_Pdf-Jsons/03_National/ALB/ALB-NREP-2021-EN.json already exists\n",
      "can't jsonify because no clean text ALB-NGP-2016-EN\n",
      "can't jsonify because no clean text ALB-NREDS-2005-EN\n",
      "can't jsonify because no clean text ALB-NREEP-2013-EN\n",
      "../02_Output/03_Pdf-Jsons/03_National/DZA directory created!\n",
      "can't jsonify because no clean text DZA-NREP-43952-EN\n",
      "../02_Output/03_Pdf-Jsons/03_National/AGO directory created!\n",
      "can't jsonify because no clean text AGO-NREP-2023-FR\n",
      "can't jsonify because no clean text AGO-SEP-2023-EN\n",
      "../02_Output/03_Pdf-Jsons/03_National/ARG directory created!\n",
      "../02_Output/03_Pdf-Jsons/03_National/ARM directory created!\n"
     ]
    }
   ],
   "source": [
    "jsonify_all(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13f288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9546fa78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
