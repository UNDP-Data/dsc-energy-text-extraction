{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Data Pipeline\n",
    "\n",
    "1. Download the updated [Document Compilation](https://docs.google.com/spreadsheets/d/1qxb6JL9f-UxLmj8dWVrWa0H8Lx4Y_HMbew35w4W25N4/edit#gid=2111530845) and rerun the scripts.\n",
    "\n",
    "2. PDF files are downloaded to `/pdf_documents`.\n",
    "\n",
    "3. Json format metadata: `/document_compilation_json/documents.json`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Category</th>\n",
       "      <th>KeyWord to Search</th>\n",
       "      <th>Document Title</th>\n",
       "      <th>Exists?</th>\n",
       "      <th>Type</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>End Year</th>\n",
       "      <th>Language</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG-CPD-2014-EN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>CPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Country programme document for Afghanistan (20...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Text</td>\n",
       "      <td>2-5 September 2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>2019</td>\n",
       "      <td>EN</td>\n",
       "      <td>https://digitallibrary.un.org/record/781748/fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG-CPD-2014-FR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>CPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Text</td>\n",
       "      <td>2-5 September 2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>2019</td>\n",
       "      <td>FR</td>\n",
       "      <td>https://digitallibrary.un.org/record/781748/fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG-CPD-2014-SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>CPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Text</td>\n",
       "      <td>2-5 September 2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>2019</td>\n",
       "      <td>SP</td>\n",
       "      <td>https://digitallibrary.un.org/record/781748/fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG-NEP-2015-EN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NEP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RENEWABLE ENERGYPOLICY</td>\n",
       "      <td>Y</td>\n",
       "      <td>Text</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>2023</td>\n",
       "      <td>EN</td>\n",
       "      <td>https://cdn.climatepolicyradar.org/navigator/A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG-NREP-2013-EN</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NREP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan Rural Renewable Energy Policy</td>\n",
       "      <td>Y</td>\n",
       "      <td>Text</td>\n",
       "      <td>April, 2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>2027</td>\n",
       "      <td>EN</td>\n",
       "      <td>https://cdn.climatepolicyradar.org/navigator/A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5818</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5823 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Code     Status Country Name Country Code Category  \\\n",
       "0      AFG-CPD-2014-EN  Completed  Afghanistan          AFG      CPD   \n",
       "1      AFG-CPD-2014-FR        NaN  Afghanistan          AFG      CPD   \n",
       "2      AFG-CPD-2014-SP        NaN  Afghanistan          AFG      CPD   \n",
       "3      AFG-NEP-2015-EN  Completed  Afghanistan          AFG      NEP   \n",
       "4     AFG-NREP-2013-EN  Completed  Afghanistan          AFG     NREP   \n",
       "...                ...        ...          ...          ...      ...   \n",
       "5818               NaN        NaN          NaN          NaN      NaN   \n",
       "5819               NaN        NaN          NaN          NaN      NaN   \n",
       "5820               NaN        NaN          NaN          NaN      NaN   \n",
       "5821               NaN        NaN          NaN          NaN      NaN   \n",
       "5822               NaN        NaN          NaN          NaN      NaN   \n",
       "\n",
       "     KeyWord to Search                                     Document Title  \\\n",
       "0                  NaN  Country programme document for Afghanistan (20...   \n",
       "1                  NaN                                                NaN   \n",
       "2                  NaN                                                NaN   \n",
       "3                  NaN                             RENEWABLE ENERGYPOLICY   \n",
       "4                  NaN          Afghanistan Rural Renewable Energy Policy   \n",
       "...                ...                                                ...   \n",
       "5818               NaN                                                NaN   \n",
       "5819               NaN                                                NaN   \n",
       "5820               NaN                                                NaN   \n",
       "5821               NaN                                                NaN   \n",
       "5822               NaN                                                NaN   \n",
       "\n",
       "     Exists?  Type    Publication Date Publication Year  Unnamed: 11  \\\n",
       "0          Y  Text  2-5 September 2014             2014          NaN   \n",
       "1          Y  Text  2-5 September 2014             2014          NaN   \n",
       "2          Y  Text  2-5 September 2014             2014          NaN   \n",
       "3          Y  Text                2015             2015          NaN   \n",
       "4          Y  Text         April, 2013             2013          NaN   \n",
       "...      ...   ...                 ...              ...          ...   \n",
       "5818     NaN   NaN                 NaN              NaN          NaN   \n",
       "5819     NaN   NaN                 NaN              NaN          NaN   \n",
       "5820     NaN   NaN                 NaN              NaN          NaN   \n",
       "5821     NaN   NaN                 NaN              NaN          NaN   \n",
       "5822     NaN   NaN                 NaN              NaN          NaN   \n",
       "\n",
       "     Start Year End Year Language  \\\n",
       "0          2015     2019       EN   \n",
       "1          2015     2019       FR   \n",
       "2          2015     2019       SP   \n",
       "3          2015     2023       EN   \n",
       "4          2017     2027       EN   \n",
       "...         ...      ...      ...   \n",
       "5818        NaN      NaN      NaN   \n",
       "5819        NaN      NaN      NaN   \n",
       "5820        NaN      NaN      NaN   \n",
       "5821        NaN      NaN      NaN   \n",
       "5822        NaN      NaN      NaN   \n",
       "\n",
       "                                                   Link  \n",
       "0     https://digitallibrary.un.org/record/781748/fi...  \n",
       "1     https://digitallibrary.un.org/record/781748/fi...  \n",
       "2     https://digitallibrary.un.org/record/781748/fi...  \n",
       "3     https://cdn.climatepolicyradar.org/navigator/A...  \n",
       "4     https://cdn.climatepolicyradar.org/navigator/A...  \n",
       "...                                                 ...  \n",
       "5818                                                NaN  \n",
       "5819                                                NaN  \n",
       "5820                                                NaN  \n",
       "5821                                                NaN  \n",
       "5822                                                NaN  \n",
       "\n",
       "[5823 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "documents = pd.read_csv('Document Compilation - UNDP SEH - All.csv')\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pypdfium2 as pdfium\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "download_directory = 'pdf_documents'\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "output = []\n",
    "fails = []\n",
    "\n",
    "for index, row in documents.iterrows():\n",
    "    \n",
    "    pdf_url = row['Link']\n",
    "    try:\n",
    "        response = requests.get(pdf_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            content_disposition = response.headers.get(\"content-disposition\")\n",
    "            if content_disposition:\n",
    "                filename = content_disposition.split(\"filename=\")[1].replace('\"','')\n",
    "            else:\n",
    "                filename = os.path.basename(urlparse(pdf_url).path)\n",
    "            download_path = os.path.join(download_directory, filename)\n",
    "\n",
    "            with open(download_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "            pdf = pdfium.PdfDocument(download_path)\n",
    "            pdf_text = ''\n",
    "            for i in range(len(pdf)):\n",
    "                width, height = pdf[i].get_size()\n",
    "                # pdf_text += pdf[i].get_textpage().get_text_range()\n",
    "                pdf_text += pdf[i].get_textpage().get_text_bounded(left=0, bottom=75, right=width, top=height-75)\n",
    "            \n",
    "            document_data = {\n",
    "                'Code': row['Code'],\n",
    "                'Status': row['Status'],\n",
    "                'Country Name': row['Country Name'],\n",
    "                'Country Code': row['Country Code'],\n",
    "                'Category': row['Category'],\n",
    "                'KeyWord to Search': row['KeyWord to Search'],\n",
    "                'Document Title': row['Document Title'],\n",
    "                'Exists?': row['Exists?'],\n",
    "                'Type': row['Type'],\n",
    "                'Publication Date': row['Publication Date'],\n",
    "                'Publication Year': row['Publication Date'],\n",
    "                'Start Year': row['Start Year'],\n",
    "                'End Year': row['End Year'],\n",
    "                'Language': row['Language'],\n",
    "                'Link': row['Link'],\n",
    "                'Content': pdf_text  # Extracted text content from PDF\n",
    "            }\n",
    "            \n",
    "            output.append(document_data)\n",
    "            print(f\"Successfully processed document with index: {index}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Failed to process document with index: {index}\")\n",
    "            fails.append(index)\n",
    "    except:\n",
    "        print(f\"Failed to download document with index: {index}\")\n",
    "        fails.append(index)\n",
    "        \n",
    "# os.makedirs('document_compilation_json', exist_ok=True)\n",
    "# json_file_path = os.path.join('document_compilation_json', \"documents.json\")\n",
    "# with open(json_file_path, \"w\") as json_file:\n",
    "#     json.dump(output, json_file)\n",
    "    \n",
    "# download_directory_path = os.path.abspath(download_directory)\n",
    "\n",
    "# print(f\"Processed {len(output)} documents, saved orginal pdf files to {download_directory_path} and saved json format with extracted text to {json_file_path}.\")\n",
    "# documents.loc[fails].to_csv('download_fails.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 751 documents, saved orginal pdf files to /Users/gaomingrui/Documents/GitHub/dsc-energy-data/pdf_documents and saved json format with extracted text to document_compilation_json/documents.json.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('document_compilation_json', exist_ok=True)\n",
    "json_file_path = os.path.join('document_compilation_json', \"documents.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(output, json_file)\n",
    "    \n",
    "download_directory_path = os.path.abspath(download_directory)\n",
    "\n",
    "print(f\"Processed {len(output)} documents, saved orginal pdf files to {download_directory_path} and saved json format with extracted text to {json_file_path}.\")\n",
    "documents.loc[fails].to_csv('download_fails.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('document_compilation_json/documents.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_noice(text):\n",
    "    cleaned_text = text.replace('\\uf0a7', ';')\n",
    "    cleaned_text = text.replace('\\r', '\\n')\n",
    "    cleaned_text = re.sub(r\"\\n\", \" \", cleaned_text)  # remove newlines\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)  # replace multiple spaces with a single space\n",
    "    # cleaned_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", cleaned_text)  # remove non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r\"http\\S+|www\\S+|ftp\\S+\", \"\", cleaned_text) # remove urls\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def remove_stopwords(text): \n",
    "    # nltk.download('stopwords') # only need to run this once\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_text = [word for word in text.split() if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "def convert_to_lowercase(text): # reduce words to their root forms\n",
    "    return text.lower()\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    # nltk.download('wordnet') only need to run this once\n",
    "    lemmatizer = WordNetLemmatizer() # tokenize the input text into words\n",
    "    words = nltk.word_tokenize(text) # lemmatize each word and collect the results in a list\n",
    "\n",
    "    original_words = []\n",
    "    lemmatized_words = []\n",
    "    for word in words:\n",
    "        original_words.append(word)\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        lemmatized_words.append(lemmatized_word)\n",
    "        # if word != lemmatized_word: # keep track of lemmatized words\n",
    "        #     print(f\"Word '{word}' changed to '{lemmatized_word}'\")\n",
    "            \n",
    "    lemmatized_text = \" \".join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "def clean(text):\n",
    "    text = remove_noice(text)\n",
    "    # text = remove_punctuation(text)\n",
    "    # text = remove_stopwords(text)\n",
    "    # text = convert_to_lowercase(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text\n",
    "\n",
    "def clean_all(row):\n",
    "    content = row['Content'] \n",
    "    return clean(content)\n",
    "\n",
    "df['clean_content'] = df.apply(clean_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all(row):\n",
    "    content = row['Content'] \n",
    "    return clean(content)\n",
    "\n",
    "df['clean_content'] = df.apply(clean_all, axis=1)\n",
    "\n",
    "import os\n",
    "json_file_path = os.path.join('document_compilation_json', \"documents_cleaned.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(df, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNDP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
